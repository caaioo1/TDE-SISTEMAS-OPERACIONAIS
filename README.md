# TDE-SISTEMAS-OPERACIONAIS
Resumo referente ao livro fundamentos 
Título: Fundamentos de Sistemas Operacionais 9a 
Autores: Caio Rodrigues, Gilson Bruno, Ryan Santos, Valgnese Sousa.
Palavras-chave: Sistemas Operacionais, Sistema de Arquivos, Implementação,  Diretórios, Alocação, Gerenciamento de Espaço, Desempenho, Recuperação, NFS,  WAFL. 
O texto enfatiza a importância da memória em sistemas de computação  modernos, descrevendo-a como um grande array de bytes, com a CPU extrai  instruções e dados de acordo com o contador do programa. Um ciclo típico de  execução de instruções é delineado, onde as instruções são  extraídas, decodificadas, e os resultados podem ser armazenados de volta na  memória. Destaca-se que a unidade de memória não tem conhecimento sobre  como os endereços são gerados ou sua finalidade, apenas respondendo às  solicitações de leitura e escrita. Além disso, são discutidos tópicos sobre o hardware básico, como os  registradores embutidos na CPU e a necessidade de memória rápida para  otimizar o acesso à memória principal. São abordadas questões de proteção de  acesso à memória, com o uso de registradores base e limite para separar os  espaços de memória de diferentes processos, garantindo segurança e evitando  interferências entre eles. O texto também trata da vinculação de endereços, destacando diferentes  métodos, como a vinculação em tempo de compilação, carga e execução, e  discute a diferença entre endereços lógicos e físicos, além de apresentar o  conceito de carga dinâmica e vinculação dinâmica, incluindo o uso de bibliotecas  compartilhadas. Essas técnicas permitem uma utilização mais eficiente da  memória, permitindo que rotinas sejam carregadas apenas quando necessárias  e facilitando a atualização e compartilhamento de bibliotecas entre diferentes  programas. 
O texto explora como a troca de processos na memória pode fazer com que o  sistema execute várias tarefas ao mesmo tempo, mas também destaca os  problemas que surgem, como o tempo que isso leva e os desafios com  operações de entrada e saída. 
Além disso, ele discute diferentes maneiras de administrar a memória, como  alocar espaços de forma contínua, proteger a memória contra acesso não  autorizado e estratégias para distribuir a memória de forma eficiente. Também  menciona questões como fragmentação de memória e como resolver esses  problemas, seja compactando a memória ou usando técnicas mais avançadas  como segmentação e paginação. Quando se trata de dispositivos móveis, o texto destaca que eles tendem a evitar  a troca de processos devido a restrições de memória, optando por fechar  aplicativos ou salvar seus estados na memória flash. 
Em resumo, o texto oferece uma visão ampla e compreensível dos desafios e  das estratégias usadas para gerenciar a memória em sistemas operacionais. A permuta de processos é uma técnica que permite transferir temporariamente  processos da memória principal para uma memória secundária, aumentando 
assim o grau de multiprogramação no sistema. Na permuta-padrão, os  processos são transferidos entre a memória principal e uma memória de  retaguarda, geralmente um disco. Essa técnica, no entanto, tem um tempo de  execução elevado devido ao tempo de transferência entre memórias. Além  disso, é restrita por fatores como a necessidade de garantir que os processos  estejam totalmente ociosos e a presença de operações de I/O pendentes. Nos sistemas operacionais modernos, a permuta-padrão não é utilizada devido  ao seu alto tempo de execução. Versões modificadas são encontradas, como no  UNIX, Linux e Windows, onde a permuta é iniciada apenas quando a memória  livre está abaixo de um valor limite, ou processos são trocados parcialmente para  diminuir o tempo de permuta. 
Nos dispositivos móveis, a permuta não é suportada devido ao uso de memória  flash, sendo substituída por estratégias de gerenciamento de memória como  solicitar que aplicativos liberem voluntariamente memória alocada ou encerrá-los  se necessário. Isso é feito para evitar problemas de espaço e garantir o bom  desempenho do dispositivo. 
A alocação de memória contígua é um método antigo para gerenciar a memória  principal de um sistema computacional. Inicialmente, a memória é dividida em  duas partições: uma para o sistema operacional e outra para os processos de  usuário. O sistema operacional geralmente é alocado na memória  baixa, próximo ao vetor de interrupções. Na alocação de memória contígua, cada processo é alocado em uma única  seção contígua da memória, o que permite uma fácil implementação da proteção  de memória. Isso é feito através do uso de um registrador de relocação e um  registrador limite, onde o primeiro contém o menor endereço físico e o segundo  define o intervalo de endereços lógicos. A MMU mapeia dinamicamente os  endereços lógicos para endereços físicos, garantindo que um processo não  acesse a memória de outro. A alocação de memória pode ser feita utilizando diferentes métodos, como o  esquema de partições múltiplas. Nesse método, a memória é dividida em  partições de tamanho fixo, cada uma podendo conter um único processo. As  brechas de memória são mantidas em uma lista pelo sistema operacional, e  processos são alocados nelas conforme necessário. Existem estratégias para alocar memória disponível aos processos, como o  primeiro-apto, mais-apto e menos-apto. Essas estratégias buscam otimizar a  utilização da memória e minimizar a fragmentação externa, que ocorre quando  há espaço livre na memória, mas ele está fragmentado em pequenas brechas. Para evitar o problema da fragmentação interna, que ocorre quando um  processo não utiliza toda a memória alocada para ele, os blocos de memória  podem ser divididos em unidades de tamanho fixo. Outra solução para a  fragmentação externa é a compactação, que envolve mover os processos e as  brechas de memória para unir toda a memória disponível em um grande bloco. Além da alocação de memória contígua, outras técnicas como segmentação e  paginação podem ser utilizadas para lidar com a fragmentação  externa, permitindo que o espaço de endereçamento dos processos seja não  contíguo. Essas técnicas proporcionam uma solução mais flexível para o  gerenciamento da memória, especialmente em sistemas onde a fragmentação 
pode ser um problema significativo. A segmentação é um método de gerenciamento de memória que permite aos  programadores visualizar a memória como um conjunto de segmentos de  tamanho variável, cada um com um propósito específico no programa. Em vez  de lidar com a memória em termos de suas propriedades físicas, os  programadores podem referenciar cada elemento do programa por um nome de  segmento e um deslocamento dentro desse segmento. 
Para implementar a segmentação, o hardware utiliza uma tabela de  segmentos, onde cada entrada contém uma base de segmento e um limite de  segmento. A base de segmento especifica o endereço físico inicial do segmento  na memória, enquanto o limite de segmento indica o tamanho do  segmento. Assim, quando um programador referencia um endereço lógico  composto por um número de segmento e um deslocamento, o hardware utiliza a  tabela de segmentos para mapear esse endereço para um endereço físico na  memória real. Por exemplo, se um programa possui cinco segmentos numerados de 0 a  4, armazenados em locais específicos da memória física, a tabela de segmentos  terá uma entrada para cada segmento, indicando sua base e limite. Quando o  programa faz uma referência a um byte em um determinado segmento, o  hardware usa a tabela de segmentos para calcular o endereço físico  correspondente na memória real. Em resumo, a segmentação fornece aos programadores uma maneira mais  natural de trabalhar com a memória, permitindo que eles se concentrem nos  segmentos do programa em vez de lidar diretamente com endereços físicos. Isso  simplifica o desenvolvimento de software e dá mais liberdade ao sistema  operacional para gerenciar a memória de forma eficiente. vs. Paginação: A segmentação e a paginação são dois esquemas de  gerenciamento de memória que permitem a alocação de espaço de endereço  não contíguo para processos. Enquanto a segmentação pode levar à  fragmentação externa e à necessidade de compactação, a paginação evita  esses problemas. Básica da Paginação: Na paginação, a memória física é dividida em blocos de  tamanho fixo chamados quadros, enquanto a memória lógica é dividida em  blocos de tamanho igual chamados páginas. Isso cria uma separação clara entre  o espaço de endereço lógico e físico. de Endereços: O mapeamento de endereços lógicos para endereços físicos é  feito usando tabelas de páginas. Cada endereço gerado pela CPU é dividido em  um número de página e um deslocamento de página, e a tabela de páginas é  usada para encontrar o endereço base de cada página na memória física. das Páginas e TLB: O tamanho das páginas geralmente é uma potência de 2, o  que simplifica a tradução de endereços. O TLB é usado para armazenar entradas  da tabela de páginas mais frequentemente acessadas, reduzindo o tempo  necessário para acessar a memória. de Memória: Bits de proteção associados a cada quadro de página são usados  para controlar o acesso à memória, garantindo que processos não acessem  áreas de memória que não lhes pertencem. 
Compartilhadas: Uma vantagem da paginação é a capacidade de compartilhar 
páginas de código comum entre processos, economizando memória física. Sua explicação detalhada abrange desde os conceitos básicos até aspectos  mais avançados, como o funcionamento do TLB e a proteção de memória. Isso  fornece uma compreensão abrangente do papel da paginação no gerenciamento  de memória de sistemas operacionais. 
O texto explora diferentes abordagens para estruturar a tabela de páginas em  sistemas operacionais. Ele fala sobre a paginação hierárquica, onde a tabela é  dividida em partes menores, como nos sistemas VAX e UltraSPARC. Para  endereçamentos de 64 bits, os esquemas hierárquicos se tornam inviáveis  devido ao grande número de entradas necessárias. Por isso, sugere-se o uso de  tabelas de páginas com hash para espaços de endereçamento maiores, onde  uma função hash mapeia páginas virtuais para quadros de página física. As  tabelas de páginas invertidas, por sua vez, associam cada página física aos processos correspondentes. Todas essas técnicas têm como objetivo otimizar o  uso da memória física e melhorar a eficiência na tradução de endereços virtuais  para físicos. Além disso, o texto menciona o Solaris, que utiliza tabelas de  páginas com hash para resolver os desafios da memória virtual em sistemas de  64 bits, e também implementa um TLB para acelerar as traduções de endereço. A arquitetura da Intel tem sido dominante nos PCs por décadas, começando com  os chips de 16 bits como o 8086 e o 8088. Posteriormente, surgiram os chips de  32 bits, conhecidos como IA-32, que incluíam os processadores Pentium. Essa  arquitetura suportava tanto segmentação quanto paginação. Mais  recentemente, a Intel desenvolveu chips de 64 bits baseados na arquitetura x86- 
64. 
No IA-32, o gerenciamento de memória envolve segmentação e paginação. A  segmentação divide o espaço de endereçamento lógico em duas partes, com  informações mantidas na LDT e na GDT. Cada entrada nessas tabelas contém  detalhes sobre um segmento específico. O endereço lógico é um par, onde o  seletor indica o segmento e outras informações. O endereço linear é gerado a  partir desses dados e usado para acessar a memória física. A paginação no IA-32 suporta páginas de 4 KB ou 4 MB, usando um esquema  de dois níveis. Os endereços lineares são traduzidos em endereços físicos  usando tabelas de páginas externas e internas. A PAE estende o suporte a  endereços físicos maiores que 4 GB, usando um esquema de três níveis. 
Na arquitetura x86-64, há suporte a endereçamento de 64 bits, com um espaço  de endereço virtual de até 48 bits. Isso permite endereçar até 16 exabytes de  memória. O esquema de paginação inclui quatro níveis de hierarquia, permitindo  tamanhos de página de 4 KB, 2 MB ou 1 GB. Os endereços virtuais têm 48  bits, mas suportam endereços físicos de até 52 bits. 
Os processadores ARM de 32 bits têm ganhado destaque nos dispositivos  móveis, como smartphones e tablets. Enquanto a Intel projeta e fabrica seus  próprios chips, a ARM licencia seus projetos para fabricantes. A Apple, por  exemplo, utiliza chips ARM em seus dispositivos móveis iPhone e iPad, e muitos  smartphones Android também adotam essa arquitetura. 
A arquitetura ARM de 32 bits suporta páginas de diferentes tamanhos, incluindo  4 KB, 16 KB, 1 MB e 16 MB . O sistema de paginação utilizado depende do  tamanho da página ou seção sendo referenciada. Para seções de 1 MB e 16 
MB, é utilizada uma paginação de um nível, enquanto páginas de 4 KB e 16 KB  são gerenciadas por uma paginação de dois níveis. O sistema de tradução de endereços da ARM inclui dois níveis de Translation  Lookaside Buffers . Os micros TLBs, localizados no nível externo, são  responsáveis por dados e instruções separadamente, e também oferecem  suporte a ASIDs . No nível interno, há um único TLB principal. A tradução de  endereços começa nos micros TLBs e, em caso de falha, passa para o TLB  principal. Se ambos os TLBs falharem, uma pesquisa na tabela de páginas é  realizada em hardware. 
Os algoritmos de gerenciamento de memória para sistemas operacionais  multiprogramados variam desde abordagens simples, como alocação  contígua, até técnicas mais complexas, como paginação e segmentação. O fator  determinante para a escolha do método em um sistema específico é o hardware  disponível. Cada endereço de memória gerado pela CPU precisa ser verificado  quanto à validade e possivelmente mapeado para um endereço físico, e essa  verificação não pode ser implementada eficientemente em  software, dependendo do hardware disponível. 
*Suporte de hardware*: Algoritmos mais simples podem ser suportados por  registradores de base ou pares de registradores base-limite, enquanto técnicas  mais complexas, como paginação e segmentação, exigem tabelas de  mapeamento. 
*Desempenho*: Quanto mais complexo o algoritmo de gerenciamento de  memória, maior pode ser o tempo necessário para mapear um endereço lógico  para um endereço físico. Algoritmos simples podem ser mais rápidos, enquanto  paginação e segmentação podem ter desempenho degradado se as tabelas de  mapeamento estiverem na memória principal. O uso de TLBs pode mitigar essa  degradação. 
*Fragmentação*: Diferentes algoritmos lidam de maneira diferente com a  fragmentação de memória, tanto interna quanto externa. 
A estrutura de armazenamento de massa desempenha um papel fundamental  na computação contemporânea devido à sua importância na manipulação e  armazenamento de grandes volumes de dados em várias áreas. Desde os  tradicionais discos rígidos até as tecnologias mais avançadas, como SSDs e  armazenamento em nuvem, houve uma progressão significativa, impulsionada  pela crescente demanda por armazenamento em massa,discutir a estrutura  física dos discos rígidos, incluindo elementos como platters, cabeças de  leitura/gravação e controladores, é essencial para entender como os dados são  armazenados e acessados. Isso envolve uma análise detalhada da disposição  geométrica dos dados nos discos, incluindo conceitos como trilhas, setores e  cilindros, e as técnicas empregadas para acessar e manipular esses dados,  como o posicionamento das cabeças e os movimentos do braço. 
A conexão dos discos aos sistemas computacionais é facilitada por diversas  interfaces, como SATA, SCSI e PCIe, cada uma com suas próprias  características em termos de taxa de transferência, latência e compatibilidade  com diferentes tipos de dispositivos de armazenamento.
Algoritmos de programação de disco, como FCFS, SSTF, SCAN e C-SCAN, são  utilizados para priorizar e otimizar as solicitações de acesso ao disco, visando  reduzir o tempo de espera e aprimorar a eficiência do sistema 
O gerenciamento de disco envolve etapas como formatação, particionamento e  criação de sistemas de arquivos, com diferentes técnicas de formatação e  sistemas de arquivos predominantes, como FAT, NTFS e ext4, cada um com  suas características e funcionalidades específicas. 
O espaço de permuta desempenha um papel crucial no contexto de sistemas de  memória virtual, permitindo a alocação e liberação de espaço de memória física  conforme necessário para otimizar o desempenho do sistema e mitigar  problemas de falta de memória. 
As configurações RAID, como RAID 0, RAID 1, RAID 5 e RAID 10, são  empregadas para melhorar o desempenho e a confiabilidade do  armazenamento, enquanto as tecnologias de armazenamento não voláteis,  como SSDs e unidades flash, oferecem vantagens e desvantagens em relação  aos discos magnéticos tradicionais, exigindo técnicas de gerenciamento e  otimização específicas, como coleta de lixo e nivelamento de desgaste, para  garantir um desempenho consistente e prolongar a vida útil dos dispositivos. 
O Capítulo 11 do livro aborda a Interface do Sistema de Arquivos, explorando  conceitos essenciais relacionados à organização, acesso e compartilhamento de  arquivos em sistemas operacionais. 
Introdução ao conceito de arquivo como uma unidade lógica de armazenamento  de dados, que pode conter informações de texto, imagem, vídeo, entre outros.  Discute-se também os atributos de arquivo, como nome, tamanho, data de  criação e permissões de acesso. 
Explanação dos diferentes métodos de acesso a arquivos, incluindo acesso  sequencial e acesso direto (random access), e suas aplicações práticas em  operações de leitura e escrita. 
Análise da estrutura hierárquica de diretórios utilizada para organizar e acessar  arquivos em sistemas de arquivos. Descrição dos métodos de implementação  de diretórios, como listas encadeadas, árvores e tabelas hash, e sua influência  na eficiência das operações de busca e acesso a arquivos. Explora-se também  a estrutura física de discos e sua relação com a organização e alocação de  arquivos em sistemas de armazenamento. 
Explicação do processo de montagem de um sistema de arquivos, que envolve  a associação de dispositivos de armazenamento com diretórios específicos no  sistema operacional. Discute-se sobre as etapas e os requisitos necessários  para montar e desmontar sistemas de arquivos, incluindo verificação de  integridade e inicialização de dispositivos. 
Abordagem das técnicas e protocolos utilizados para compartilhar arquivos entre  diferentes usuários e sistemas em redes de computadores. Explora-se os 
modelos de compartilhamento de arquivos, como acesso direto, acesso indireto  (através de servidores de arquivos) e acesso remoto (via protocolos de rede). 
Discussão sobre os mecanismos de proteção de arquivos e diretórios, incluindo  permissões de acesso, controle de acesso baseado em papéis (RBAC) e  criptografia. Explora-se as políticas de segurança adotadas para garantir a  integridade, confidencialidade e disponibilidade dos dados armazenados em  sistemas de arquivos. 
A estrutura do sistema de arquivos compreende elementos como metadados,  blocos de dados e estruturas de diretório, com diferentes abordagens de  organização de arquivos e diretórios, como árvores, tabelas e grafos. A  implementação do sistema de arquivos envolve técnicas e algoritmos para  operações de leitura/gravação, controle de acesso e proteção de dados, com  exemplos de sistemas de arquivos comuns como FAT, NTFS e ext4. 
Os diretórios são essenciais para a organização e acesso aos arquivos, com  diferentes estruturas e técnicas de implementação, como listas lineares, árvores  e tabelas hash. Os métodos de alocação de espaço em disco incluem alocação  contígua, encadeada e indexada, cada um com suas vantagens e desvantagens  em termos de fragmentação e desempenho. 
O gerenciamento do espaço livre em disco é crítico para otimizar o uso do  espaço disponível, com técnicas como bitmap, listas ligadas e mapas de bits  agrupados. A eficiência e o desempenho dos sistemas de arquivos são  influenciados por fatores como taxa de transferência, latência e algoritmos de  otimização de desempenho, como cache de disco e pré-busca de dados. 
A recuperação de sistemas de arquivos em caso de falhas é assegurada por  estratégias como log de transações e pontos de verificação, enquanto protocolos  como NFS (Network File System) facilitam o compartilhamento de arquivos em  ambientes de rede. Um exemplo notável de sistema de arquivos é o WAFL (Write  Anywhere File Layout), utilizado em dispositivos de armazenamento da NetApp,  que apresenta características distintivas como alocação de blocos de dados e  instantâneos (snapshots). 
No Capítulo 8, exploramos os mecanismos de sincronização e comunicação  entre processos, cruciais para garantir a cooperação e a coordenação entre  diferentes partes de um sistema computacional. 
O Capítulo 9 nos introduziu aos princípios de escalonamento de processos,  discutindo algoritmos e estratégias para otimizar o uso dos recursos do sistema,  garantindo eficiência e equidade no compartilhamento da CPU entre os  processos. 
Do Capítulo 10, aprendemos sobre a estrutura de armazenamento de massa,  desde a visão geral dos dispositivos até técnicas avançadas de gerenciamento  de disco e implementação de RAID.
No Capítulo 11, exploramos a interface do sistema de arquivos, incluindo  conceitos como organização, montagem do sistema de arquivos, métodos de  acesso, compartilhamento de arquivos e mecanismos de proteção. 
Por fim, o Capítulo 12 abordou a implementação do sistema de arquivos,  detalhando aspectos como estrutura de diretórios, métodos de alocação de  espaço, eficiência e desempenho, recuperação de dados e tecnologias de  armazenamento estável. 
#include <windows.h> 
#include <stdio.h> 
int main(int argc, char *argv[]) 
{ 
HANDLE hFile, hMapFile; 
LPVOID lpMapAddress; 
hFile = CreateFile(“temp.txt”, /* nome do arquivo */ 
GENERIC READ | GENERIC WRITE, /* acesso de leitura/gravação */ 0, /* sem compartilhamento do arquivo */ 
NULL, /* segurança default */ 
OPEN_ALWAYS, /* abre arquivo novo ou existente */ 
FILE_ATTRIBUTE_NORMAL, /* atributos de arquivo rotineiros */ NULL); /* sem template de arquivo */ 
hMapFile = CreateFileMapping(hFile, /* manipulador do arquivo */ NULL, /* segurança default */ 
PAGE_READWRITE, /* acesso de leitura/gravação a páginas mapeadas */ 
0, /* mapeia arquivo inteiro */ 
0, 
TEXT(“SharedObject”)); /* objeto de memória compartilhada nomeado */ 
lpMapAddress = MapViewOfFile(hMapFile, /* manipulador do objeto mapeado */ 
FILE_MAP_ALL_ACCESS, /* acesso de leitura/gravação */ 
0, /* visão mapeada do arquivo inteiro */ 
0, 
0); 
/* grava na memória compartilhada */ 
sprintf(lpMapAddress,”Shared memory message”); 
UnmapViewOfFile(lpMapAddress); 
CloseHandle(hFile); 
CloseHandle(hMapFile); 
} 
Figura 9.24 Produtor gravando na memória compartilhada usando a API  Windows. 
#include <windows.h> 
#include <stdio.h> 
int main(int argc, char *argv[]) 
{ 
HANDLE hMapFile; 
LPVOID lpMapAddress;
hMapFile = OpenFileMapping(FILE_MAP_ALL_ACCESS, /* acesso de leitura/gravação */ 
FALSE, /* sem herança */ 
TEXT(“SharedObject”)); /* nome do objeto de arquivo mapeado */ lpMapAddress = MapViewOfFile(hMapFile, /* manipulador do objeto mapeado */ 
FILE_MAP_ALL_ACCESS, /* acesso de leitura/gravação */ 0, /* visão mapeada do arquivo inteiro */ 
0, 
0); 
/* lê a partir da memória compartilhada */ 
printf(“Read message %s”, lpMapAddress); 
UnmapViewOfFile(lpMapAddress); 
CloseHandle(hMapFile); 
Código referente à parte 9 no capitulo 9.7.2
